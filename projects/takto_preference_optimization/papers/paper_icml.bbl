\begin{thebibliography}{7}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Christiano et~al.(2017)Christiano, Leike, Brown, Martic, Legg, and
  Amodei]{christiano2017deep}
Paul~F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario
  Amodei.
\newblock Deep reinforcement learning from human preferences.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Christopoulou et~al.(2024)Christopoulou, Cardenas, Lampouras,
  Bou-Ammar, and Wang]{christopoulou2024sparsepo}
Fenia Christopoulou, Ronald Cardenas, Gerasimos Lampouras, Haitham Bou-Ammar,
  and Jun Wang.
\newblock Sparsepo: Controlling preference alignment of llms via sparse token
  masks.
\newblock \emph{arXiv preprint arXiv:2410.05102}, 2024.

\bibitem[Ethayarajh et~al.(2024)Ethayarajh, Xu, Muennighoff, Jurafsky, and
  Kiela]{ethayarajh2024kto}
Kawin Ethayarajh, Winnie Xu, Niklas Muennighoff, Dan Jurafsky, and Douwe Kiela.
\newblock Kto: Model alignment as prospect theoretic optimization.
\newblock \emph{arXiv preprint arXiv:2402.01306}, 2024.

\bibitem[Liu et~al.(2025)Liu, Bai, Lu, et~al.]{liu2024tis}
Aiwei Liu, Haoping Bai, Zhiyun Lu, et~al.
\newblock Tis-dpo: Token-level importance sampling for direct preference
  optimization with estimated weights.
\newblock \emph{International Conference on Learning Representations}, 2025.

\bibitem[Meng et~al.(2024)Meng, Xia, and Chen]{meng2024simpo}
Yu~Meng, Mengzhou Xia, and Danqi Chen.
\newblock Simpo: Simple preference optimization with a reference-free reward.
\newblock \emph{Advances in Neural Information Processing Systems}, 2024.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, et~al.]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 27730--27744, 2022.

\bibitem[Rafailov et~al.(2023)Rafailov, Sharma, Mitchell, Ermon, Manning, and
  Finn]{rafailov2023direct}
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher~D
  Manning, and Chelsea Finn.
\newblock Direct preference optimization: Your language model is secretly a
  reward model.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2023.

\end{thebibliography}
